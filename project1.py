# -*- coding: utf-8 -*-
"""PROJECT1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nOS7vAzJ4jQC2Ebq0ULfp4LCCPHDFsrp
"""

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import cv2

"""**GET the photo**"""

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

image  = mpimg.imread('WhatsApp Image 2021-05-05 at 2.41.47 PM.jpg')
plt.imshow(image)

def grayscale(img):
  
    gray=cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    plt.imshow(gray, cmap='gray')
    return gray

gray = grayscale(image)
image.shape

def hls_select(image, thresh=(0, 255)):
    # 1) Convert to HLS color space
    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)
    H = hls[:,:,0]
    L = hls[:,:,1]
    S = hls[:,:,2]
    # 2) Apply a threshold to the L channel
    thresh = (90, 255)
    binary = np.zeros_like(L)
    binary[(L > thresh[0]) & (L <= thresh[1])] = 1
    # 3) Return a binary image of threshold result
     # placeholder line
    return binary
    
# Optional TODO - tune the threshold to try to match the above image!    
hls_binary = hls_select(image, thresh=(0, 270))

# Plot the result
f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))
f.tight_layout()
ax1.imshow(image)
ax1.set_title('Original Image', fontsize=50)
ax2.imshow(hls_binary, cmap='gray')
ax2.set_title('Thresholded L', fontsize=50)
plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)

#fisrt we crop the region of intrest
def ver(img):
    imshape = img.shape
    vertices = np.array([[(0,350),(449, 350), (0, 600), (449,600)]], dtype=np.int32)
    #vertices = np.array([[130, imshape[0]], 
                # [625, imshape[0]*0.6], 
                   #  [700, imshape[0]*0.6], 
                    # [1200, imshape[0]]], dtype= np.int32)
    return vertices 
ver(hls_binary)


def region_of_interest(img, vertices):
    """
    Applies an image mask.
    
    Only keeps the region of the image defined by the polygon
    formed from `vertices`. The rest of the image is set to black.
    `vertices` should be a numpy array of integer points.
    """
    #defining a blank mask to start with
    mask = np.zeros_like(img)   
    
    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image
    if len(img.shape) > 2:
        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image
        ignore_mask_color = (255,) * channel_count
    else:
        ignore_mask_color =255
        
    #filling pixels inside the polygon defined by "vertices" with the fill color    
    cv2.fillPoly(mask, vertices, ignore_mask_color)
    
    #returning the image only where mask pixels are nonzero
    masked_image = cv2.bitwise_and(img, mask)
    return masked_image

im = region_of_interest(hls_binary, ver(hls_binary))

plt.imshow(im)

img = cv2.imread(image)
crop_img = img[350:600, 0:449]
cv2.imshow("cropped", crop_img)
cv2.waitKey(0)

img = image
grid_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
grid_HSV = cv2.cvtColor(grid_RGB, cv2.COLOR_RGB2HSV)
 ##Green color ####
#lower_green = np.array([45, 150, 50])
#upper_green = np.array([80, 255, 255])

#Purple
lower_green = np.array([150, 60, 20])
upper_green = np.array([298, 255, 255])

mask = cv2.inRange(grid_HSV, lower_green, upper_green)
plt.imshow(grid_HSV)

!pip install easyocr --no-deps # Colab already has all dependencies

import cv2
from collections import defaultdict
from PIL import Image
from datetime import datetime
from easyocr import Reader
import re
import Jetson.GPIO as GPIO
import time 


def cleanup_text(text):
    # strip out non-ASCII text so we can draw the text on the image
    # using OpenCV
    return "".join([c if ord(c) < 128 else "" for c in text]).strip()

#LED PIN 
led_pin = 5 #TO BE EDIT accordingly (green)
led_pin2 = 7 #RED
GPIO.setmode(GPIO.BOARD) 
GPIO.setup(led_pin, GPIO.OUT, initial=GPIO.LOW)
GPIO.setup(led_pin2, GPIO.OUT, initial=GPIO.LOW)

# Open the camera
cap = cv2.VideoCapture(0)

found = False
final_frame = None

reader = Reader(["en", "ar"], gpu=True)

while (True):

    # Capture the video frame
    # by frame
    ret, img_org = cap.read()
    cv2.imshow('frame', img_org)

    results = reader.readtext(img_org)
    # print(results)

    tot_results = len(results)
    for i in range(tot_results):
        # unpack the bounding box
        bbox = results[i][0]
        text = results[i][1]
        (tl, tr, br, bl) = bbox
        tl = (int(tl[0]), int(tl[1]))
        tr = (int(tr[0]), int(tr[1]))
        br = (int(br[0]), int(br[1]))
        bl = (int(bl[0]), int(bl[1]))

        # cleanup the text and draw the box surrounding the text along
        # with the OCR'd text itself
        text = cleanup_text(text)

        # print(d['text'][i])
        if 'update' in text.lower():
            try:

                time = ' '.join([x[1] for x in results][i:i + 3])

                # print(time)
                match = re.search(r'\d{2}.*\d{2}:\d{2}', time)

                format = "%d %b, %H:%M"
                # print(match)
                dt = datetime.strptime(match.group(), format)
                dt = dt.replace(year=datetime.now().year)
            except:
                continue
            final_frame = img_org
            cv2.imwrite('camera_new.jpg', img_org)
            # print('camera_new made!')
            found = True

            difference = (datetime.now() - dt).total_seconds() / 60.0

            # we can set the time limit in minutes here
            max_minute = 10
            if difference > max_minute:
                print("Difference is", difference, "minutes, Max difference allowed is", max_minute, "minutes")
                print("PERMISSION DENIED")
                im = Image.open(r'red_x.png')
                GPIO.output(led_pin2, GPIO.HIGH)
                im.show()
                time.sleep(2) 
                GPIO.output(led_pin2, GPIO.LOW)
                exit(-1)

            # Color Check

            # recalibrating to cater for resizing image in start
            tl = (int(tl[0]) - 5, int(tl[1]) - 15)
            br = (int(br[0]) - 15, int(br[1]) - 15)

            im = Image.open('camera_new.jpg')
            im = im.crop((tl[0], tl[1], br[0], br[1]))

            by_color = defaultdict(int)
            for pixel in im.getdata():
                by_color[pixel] += 1

            # print(by_color)
            # print(max(by_color, key=by_color.get))
            max_val = max(by_color, key=by_color.get)

            if max_val[1] > max_val[0] and max_val[1] > max_val[2]:
                print("OPEN DOOR")
                im = Image.open(r'checkmark_green.jpg')
                GPIO.output(led_pin, GPIO.HIGH)
                im.show()
                time.sleep(2) 
                GPIO.output(led_pin, GPIO.LOW)
            else:
                print("PERMISSION DENIED")
                im = Image.open(r'red_x.png')
                GPIO.output(led_pin2, GPIO.HIGH)
                im.show()
                time.sleep(2) 
                GPIO.output(led_pin2, GPIO.LOW)
                

    # the 'q' button is set as the
    # quitting button you may use any
    # desired button of your choice
    if cv2.waitKey(1) & 0xFF == ord('q') or found:
        break

cap.release()

# close all the opened windows
cv2.destroyAllWindows()